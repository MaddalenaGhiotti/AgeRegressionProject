{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM CROP - MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and data loading from .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import seaborn as sn  #Per heatmap\n",
    "import time\n",
    "import scipy as sp\n",
    "import os\n",
    "import librosa as lb\n",
    "from random import randrange\n",
    "\n",
    "#sklearn\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures, LabelEncoder,OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>mean_pitch</th>\n",
       "      <th>max_pitch</th>\n",
       "      <th>min_pitch</th>\n",
       "      <th>jitter</th>\n",
       "      <th>shimmer</th>\n",
       "      <th>energy</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>tempo</th>\n",
       "      <th>hnr</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_pauses</th>\n",
       "      <th>silence_duration</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22050</td>\n",
       "      <td>24.0</td>\n",
       "      <td>female</td>\n",
       "      <td>arabic</td>\n",
       "      <td>1821.69060</td>\n",
       "      <td>3999.7170</td>\n",
       "      <td>145.43066</td>\n",
       "      <td>0.013795</td>\n",
       "      <td>0.082725</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>0.210093</td>\n",
       "      <td>3112.257251</td>\n",
       "      <td>[151.99908088]</td>\n",
       "      <td>-123.999726</td>\n",
       "      <td>69</td>\n",
       "      <td>281</td>\n",
       "      <td>39</td>\n",
       "      <td>23.846893</td>\n",
       "      <td>1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22050</td>\n",
       "      <td>22.5</td>\n",
       "      <td>female</td>\n",
       "      <td>hungarian</td>\n",
       "      <td>1297.81870</td>\n",
       "      <td>3998.8590</td>\n",
       "      <td>145.37268</td>\n",
       "      <td>0.025349</td>\n",
       "      <td>0.096242</td>\n",
       "      <td>0.007819</td>\n",
       "      <td>0.078849</td>\n",
       "      <td>1688.016389</td>\n",
       "      <td>[129.19921875]</td>\n",
       "      <td>-86.928478</td>\n",
       "      <td>69</td>\n",
       "      <td>281</td>\n",
       "      <td>21</td>\n",
       "      <td>19.388662</td>\n",
       "      <td>2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22050</td>\n",
       "      <td>22.0</td>\n",
       "      <td>female</td>\n",
       "      <td>portuguese</td>\n",
       "      <td>1332.85240</td>\n",
       "      <td>3998.8025</td>\n",
       "      <td>145.42395</td>\n",
       "      <td>0.019067</td>\n",
       "      <td>0.119456</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.105365</td>\n",
       "      <td>2576.901706</td>\n",
       "      <td>[117.45383523]</td>\n",
       "      <td>-98.450670</td>\n",
       "      <td>69</td>\n",
       "      <td>281</td>\n",
       "      <td>1</td>\n",
       "      <td>21.640998</td>\n",
       "      <td>3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22050</td>\n",
       "      <td>22.0</td>\n",
       "      <td>female</td>\n",
       "      <td>english</td>\n",
       "      <td>1430.34990</td>\n",
       "      <td>3998.4510</td>\n",
       "      <td>147.98083</td>\n",
       "      <td>0.017004</td>\n",
       "      <td>0.102389</td>\n",
       "      <td>0.022371</td>\n",
       "      <td>0.173701</td>\n",
       "      <td>3269.751413</td>\n",
       "      <td>[117.45383523]</td>\n",
       "      <td>-56.459762</td>\n",
       "      <td>69</td>\n",
       "      <td>281</td>\n",
       "      <td>9</td>\n",
       "      <td>19.644127</td>\n",
       "      <td>4.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22050</td>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>dutch</td>\n",
       "      <td>1688.72340</td>\n",
       "      <td>3998.6113</td>\n",
       "      <td>145.44772</td>\n",
       "      <td>0.028027</td>\n",
       "      <td>0.124831</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.107279</td>\n",
       "      <td>1930.897375</td>\n",
       "      <td>[112.34714674]</td>\n",
       "      <td>-80.349204</td>\n",
       "      <td>69</td>\n",
       "      <td>281</td>\n",
       "      <td>11</td>\n",
       "      <td>18.041905</td>\n",
       "      <td>5.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>22050</td>\n",
       "      <td>24.0</td>\n",
       "      <td>male</td>\n",
       "      <td>english</td>\n",
       "      <td>1641.14930</td>\n",
       "      <td>3999.1616</td>\n",
       "      <td>145.39359</td>\n",
       "      <td>0.023647</td>\n",
       "      <td>0.115361</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.111799</td>\n",
       "      <td>2188.853478</td>\n",
       "      <td>[184.5703125]</td>\n",
       "      <td>-100.921055</td>\n",
       "      <td>69</td>\n",
       "      <td>281</td>\n",
       "      <td>11</td>\n",
       "      <td>17.461406</td>\n",
       "      <td>2929.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>22050</td>\n",
       "      <td>15.0</td>\n",
       "      <td>female</td>\n",
       "      <td>igbo</td>\n",
       "      <td>1089.60050</td>\n",
       "      <td>3984.6550</td>\n",
       "      <td>145.58409</td>\n",
       "      <td>0.015317</td>\n",
       "      <td>0.126740</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.070508</td>\n",
       "      <td>2712.362323</td>\n",
       "      <td>[83.35433468]</td>\n",
       "      <td>6.757283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.509206</td>\n",
       "      <td>2930.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>22050</td>\n",
       "      <td>17.0</td>\n",
       "      <td>female</td>\n",
       "      <td>igbo</td>\n",
       "      <td>994.46484</td>\n",
       "      <td>3989.1785</td>\n",
       "      <td>148.97475</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>0.103535</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.058442</td>\n",
       "      <td>2248.698477</td>\n",
       "      <td>[89.10290948]</td>\n",
       "      <td>-53.913449</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.645034</td>\n",
       "      <td>2931.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>22050</td>\n",
       "      <td>18.0</td>\n",
       "      <td>male</td>\n",
       "      <td>arabic</td>\n",
       "      <td>1600.00820</td>\n",
       "      <td>3999.7559</td>\n",
       "      <td>145.36101</td>\n",
       "      <td>0.019571</td>\n",
       "      <td>0.100946</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.115139</td>\n",
       "      <td>1834.596924</td>\n",
       "      <td>[143.5546875]</td>\n",
       "      <td>-96.143090</td>\n",
       "      <td>69</td>\n",
       "      <td>281</td>\n",
       "      <td>19</td>\n",
       "      <td>16.346848</td>\n",
       "      <td>2932.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>22050</td>\n",
       "      <td>18.0</td>\n",
       "      <td>female</td>\n",
       "      <td>igbo</td>\n",
       "      <td>690.28046</td>\n",
       "      <td>3988.2874</td>\n",
       "      <td>149.26643</td>\n",
       "      <td>0.014833</td>\n",
       "      <td>0.096168</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.042133</td>\n",
       "      <td>1440.227098</td>\n",
       "      <td>[83.35433468]</td>\n",
       "      <td>-89.464755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.275556</td>\n",
       "      <td>2933.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2933 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sampling_rate   age  gender   ethnicity  mean_pitch  max_pitch  \\\n",
       "Id                                                                     \n",
       "0             22050  24.0  female      arabic  1821.69060  3999.7170   \n",
       "1             22050  22.5  female   hungarian  1297.81870  3998.8590   \n",
       "2             22050  22.0  female  portuguese  1332.85240  3998.8025   \n",
       "3             22050  22.0  female     english  1430.34990  3998.4510   \n",
       "4             22050  22.0    male       dutch  1688.72340  3998.6113   \n",
       "...             ...   ...     ...         ...         ...        ...   \n",
       "2928          22050  24.0    male     english  1641.14930  3999.1616   \n",
       "2929          22050  15.0  female        igbo  1089.60050  3984.6550   \n",
       "2930          22050  17.0  female        igbo   994.46484  3989.1785   \n",
       "2931          22050  18.0    male      arabic  1600.00820  3999.7559   \n",
       "2932          22050  18.0  female        igbo   690.28046  3988.2874   \n",
       "\n",
       "      min_pitch    jitter   shimmer    energy  zcr_mean  \\\n",
       "Id                                                        \n",
       "0     145.43066  0.013795  0.082725  0.002254  0.210093   \n",
       "1     145.37268  0.025349  0.096242  0.007819  0.078849   \n",
       "2     145.42395  0.019067  0.119456  0.002974  0.105365   \n",
       "3     147.98083  0.017004  0.102389  0.022371  0.173701   \n",
       "4     145.44772  0.028027  0.124831  0.005369  0.107279   \n",
       "...         ...       ...       ...       ...       ...   \n",
       "2928  145.39359  0.023647  0.115361  0.001879  0.111799   \n",
       "2929  145.58409  0.015317  0.126740  0.000339  0.070508   \n",
       "2930  148.97475  0.009677  0.103535  0.001464  0.058442   \n",
       "2931  145.36101  0.019571  0.100946  0.004451  0.115139   \n",
       "2932  149.26643  0.014833  0.096168  0.003675  0.042133   \n",
       "\n",
       "      spectral_centroid_mean           tempo         hnr  num_words  \\\n",
       "Id                                                                    \n",
       "0                3112.257251  [151.99908088] -123.999726         69   \n",
       "1                1688.016389  [129.19921875]  -86.928478         69   \n",
       "2                2576.901706  [117.45383523]  -98.450670         69   \n",
       "3                3269.751413  [117.45383523]  -56.459762         69   \n",
       "4                1930.897375  [112.34714674]  -80.349204         69   \n",
       "...                      ...             ...         ...        ...   \n",
       "2928             2188.853478   [184.5703125] -100.921055         69   \n",
       "2929             2712.362323   [83.35433468]    6.757283          0   \n",
       "2930             2248.698477   [89.10290948]  -53.913449          1   \n",
       "2931             1834.596924   [143.5546875]  -96.143090         69   \n",
       "2932             1440.227098   [83.35433468]  -89.464755          0   \n",
       "\n",
       "      num_characters  num_pauses  silence_duration      path  \n",
       "Id                                                            \n",
       "0                281          39         23.846893     1.wav  \n",
       "1                281          21         19.388662     2.wav  \n",
       "2                281           1         21.640998     3.wav  \n",
       "3                281           9         19.644127     4.wav  \n",
       "4                281          11         18.041905     5.wav  \n",
       "...              ...         ...               ...       ...  \n",
       "2928             281          11         17.461406  2929.wav  \n",
       "2929               0           1          1.509206  2930.wav  \n",
       "2930               9           1          1.645034  2931.wav  \n",
       "2931             281          19         16.346848  2932.wav  \n",
       "2932               0           4          2.275556  2933.wav  \n",
       "\n",
       "[2933 rows x 19 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/development.csv', index_col=0)\n",
    "data['path'] = data['path'].map(lambda x: x.split('/')[1])\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethnicity subgroups identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 409,    2,    1,   39,    8,    5,    2,    3,    3,    3,    1,\n",
       "          8,    5,   19,    9,   16,    7,    7,    1,    4,    1,    2,\n",
       "          9,    8,   27,   66,   26,    6,    5,    7,    2,   58,    1,\n",
       "         52,   56,    6,   51,    5,    9,    4,    8,    4,    1,    2,\n",
       "          3,    3,   15,    1,    6,    2,   28,    3,   55,   28,    3,\n",
       "          1,   44,    1,    1,    5,    4,    5,    1,    1,    1,    2,\n",
       "          6,    3,   11,   16,    1,    1,    1,    1,    1,    1, 1710])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 69 281]\n"
     ]
    }
   ],
   "source": [
    "sentence_feat = data.loc[:,['num_words','num_characters']].values\n",
    "uniq, ind, count= np.unique(np.array(sentence_feat), return_counts=True, return_inverse=True, axis=0)\n",
    "display(count)\n",
    "print(uniq[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide between long and short audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>mean_pitch</th>\n",
       "      <th>jitter</th>\n",
       "      <th>shimmer</th>\n",
       "      <th>energy</th>\n",
       "      <th>zcr_mean</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>tempo</th>\n",
       "      <th>hnr</th>\n",
       "      <th>silence_duration</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1821.69060</td>\n",
       "      <td>0.013795</td>\n",
       "      <td>0.082725</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>0.210093</td>\n",
       "      <td>3112.257251</td>\n",
       "      <td>151.999081</td>\n",
       "      <td>-123.999726</td>\n",
       "      <td>23.846893</td>\n",
       "      <td>1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1297.81870</td>\n",
       "      <td>0.025349</td>\n",
       "      <td>0.096242</td>\n",
       "      <td>0.007819</td>\n",
       "      <td>0.078849</td>\n",
       "      <td>1688.016389</td>\n",
       "      <td>129.199219</td>\n",
       "      <td>-86.928478</td>\n",
       "      <td>19.388662</td>\n",
       "      <td>2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1332.85240</td>\n",
       "      <td>0.019067</td>\n",
       "      <td>0.119456</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.105365</td>\n",
       "      <td>2576.901706</td>\n",
       "      <td>117.453835</td>\n",
       "      <td>-98.450670</td>\n",
       "      <td>21.640998</td>\n",
       "      <td>3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1430.34990</td>\n",
       "      <td>0.017004</td>\n",
       "      <td>0.102389</td>\n",
       "      <td>0.022371</td>\n",
       "      <td>0.173701</td>\n",
       "      <td>3269.751413</td>\n",
       "      <td>117.453835</td>\n",
       "      <td>-56.459762</td>\n",
       "      <td>19.644127</td>\n",
       "      <td>4.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1688.72340</td>\n",
       "      <td>0.028027</td>\n",
       "      <td>0.124831</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.107279</td>\n",
       "      <td>1930.897375</td>\n",
       "      <td>112.347147</td>\n",
       "      <td>-80.349204</td>\n",
       "      <td>18.041905</td>\n",
       "      <td>5.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1641.14930</td>\n",
       "      <td>0.023647</td>\n",
       "      <td>0.115361</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.111799</td>\n",
       "      <td>2188.853478</td>\n",
       "      <td>184.570312</td>\n",
       "      <td>-100.921055</td>\n",
       "      <td>17.461406</td>\n",
       "      <td>2929.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1089.60050</td>\n",
       "      <td>0.015317</td>\n",
       "      <td>0.126740</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.070508</td>\n",
       "      <td>2712.362323</td>\n",
       "      <td>83.354335</td>\n",
       "      <td>6.757283</td>\n",
       "      <td>1.509206</td>\n",
       "      <td>2930.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>994.46484</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>0.103535</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.058442</td>\n",
       "      <td>2248.698477</td>\n",
       "      <td>89.102909</td>\n",
       "      <td>-53.913449</td>\n",
       "      <td>1.645034</td>\n",
       "      <td>2931.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1600.00820</td>\n",
       "      <td>0.019571</td>\n",
       "      <td>0.100946</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.115139</td>\n",
       "      <td>1834.596924</td>\n",
       "      <td>143.554688</td>\n",
       "      <td>-96.143090</td>\n",
       "      <td>16.346848</td>\n",
       "      <td>2932.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>690.28046</td>\n",
       "      <td>0.014833</td>\n",
       "      <td>0.096168</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.042133</td>\n",
       "      <td>1440.227098</td>\n",
       "      <td>83.354335</td>\n",
       "      <td>-89.464755</td>\n",
       "      <td>2.275556</td>\n",
       "      <td>2933.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2933 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  gender ethnicity  mean_pitch    jitter   shimmer    energy  \\\n",
       "Id                                                                       \n",
       "0     24.0       0         1  1821.69060  0.013795  0.082725  0.002254   \n",
       "1     22.5       0         1  1297.81870  0.025349  0.096242  0.007819   \n",
       "2     22.0       0         1  1332.85240  0.019067  0.119456  0.002974   \n",
       "3     22.0       0         1  1430.34990  0.017004  0.102389  0.022371   \n",
       "4     22.0       1         1  1688.72340  0.028027  0.124831  0.005369   \n",
       "...    ...     ...       ...         ...       ...       ...       ...   \n",
       "2928  24.0       1         1  1641.14930  0.023647  0.115361  0.001879   \n",
       "2929  15.0       0         0  1089.60050  0.015317  0.126740  0.000339   \n",
       "2930  17.0       0         0   994.46484  0.009677  0.103535  0.001464   \n",
       "2931  18.0       1         1  1600.00820  0.019571  0.100946  0.004451   \n",
       "2932  18.0       0         0   690.28046  0.014833  0.096168  0.003675   \n",
       "\n",
       "      zcr_mean  spectral_centroid_mean       tempo         hnr  \\\n",
       "Id                                                               \n",
       "0     0.210093             3112.257251  151.999081 -123.999726   \n",
       "1     0.078849             1688.016389  129.199219  -86.928478   \n",
       "2     0.105365             2576.901706  117.453835  -98.450670   \n",
       "3     0.173701             3269.751413  117.453835  -56.459762   \n",
       "4     0.107279             1930.897375  112.347147  -80.349204   \n",
       "...        ...                     ...         ...         ...   \n",
       "2928  0.111799             2188.853478  184.570312 -100.921055   \n",
       "2929  0.070508             2712.362323   83.354335    6.757283   \n",
       "2930  0.058442             2248.698477   89.102909  -53.913449   \n",
       "2931  0.115139             1834.596924  143.554688  -96.143090   \n",
       "2932  0.042133             1440.227098   83.354335  -89.464755   \n",
       "\n",
       "      silence_duration      path  \n",
       "Id                                \n",
       "0            23.846893     1.wav  \n",
       "1            19.388662     2.wav  \n",
       "2            21.640998     3.wav  \n",
       "3            19.644127     4.wav  \n",
       "4            18.041905     5.wav  \n",
       "...                ...       ...  \n",
       "2928         17.461406  2929.wav  \n",
       "2929          1.509206  2930.wav  \n",
       "2930          1.645034  2931.wav  \n",
       "2931         16.346848  2932.wav  \n",
       "2932          2.275556  2933.wav  \n",
       "\n",
       "[2933 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.loc[ind==76,'ethnicity'] = 1\n",
    "data.loc[ind!=76,'ethnicity'] = 0\n",
    "clean_data = data.drop(columns=['num_words','num_characters','num_pauses','sampling_rate','max_pitch','min_pitch'])\n",
    "clean_data['tempo'] = clean_data['tempo'].map(lambda x: float(x[1:-1]))\n",
    "clean_data['gender'] = clean_data['gender'].map(lambda x: 1 if x=='male' else 0)\n",
    "display(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_long = clean_data[clean_data['ethnicity']==1].drop(columns=['ethnicity'])\n",
    "data_short = clean_data[clean_data['ethnicity']==0].drop(columns=['ethnicity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "SAMPLE_RATE = 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide in train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_long_train, data_long_val = train_test_split(data_long, test_size=0.2, random_state=RANDOM_SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction - Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silence_removal(audio_array, threshold=60, ref=np.max, aggregate=np.max):\n",
    "    \"\"\"Remove silence from the audio array.\"\"\"\n",
    "    db = lb.core.amplitude_to_db(audio_array, ref=ref, top_db=None)\n",
    "    if db.ndim > 1:\n",
    "        db = np.apply_over_axes(aggregate, db, range(db.ndim - 1))\n",
    "        db = np.squeeze(db, axis=tuple(range(db.ndim - 1)))\n",
    "    nonzero = np.flatnonzero(db > -threshold)\n",
    "    return audio_array[nonzero]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(audio_files, folder_path, sample_rate,silence_threshold=60):\n",
    "    \"\"\"Load audio files and remove silence\"\"\"\n",
    "    time_stamps = []\n",
    "    audio_arrays = {}\n",
    "    for file_name in audio_files:\n",
    "        if file_name.endswith(\".wav\"):\n",
    "            audio_array = lb.load(folder_path + file_name)\n",
    "            #Trim leading and trailing silence\n",
    "            trimmed_audio_array= lb.effects.trim(audio_array[0])\n",
    "            #Remove silence within the audio\n",
    "            noSilence = silence_removal(trimmed_audio_array[0], threshold=silence_threshold, ref=np.max(trimmed_audio_array[0]), aggregate=np.max(trimmed_audio_array[0]))\n",
    "            time_stamps.append(len(noSilence))\n",
    "            audio_arrays[file_name] = noSilence            \n",
    "    return (audio_arrays, np.array(time_stamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_time_mfcc(mfcc,num_buckets):\n",
    "    \"\"\"Standardize the number of mfccs of an audio to given value\"\"\"\n",
    "    reduced_list =[]\n",
    "    existing_int = mfcc.shape[1]\n",
    "    for i in range(0,existing_int-(existing_int%num_buckets),existing_int//num_buckets):  #Divide audio in num_buckets intervals and mean within them\n",
    "        reduced_list.append(np.mean(mfcc[:, i:i+(mfcc.shape[1]//num_buckets)], axis=1).flatten())\n",
    "    return np.array(reduced_list).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_all(mfcc_dict,num_buckets):\n",
    "    \"\"\"Standardize the number of mfccs across the audios with different lengths\"\"\"\n",
    "    standard_mfccs = {}\n",
    "    for name, mfcc in mfcc_dict.items():\n",
    "        standard_mfccs[name] = standardize_time_mfcc(mfcc,num_buckets)\n",
    "    return standard_mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_all(mfcc_dict):\n",
    "    \"\"\"From 2d mfccs to 1d dataframe\"\"\"\n",
    "    reshaped_mfccs = {}\n",
    "    for name, mfcc in mfcc_dict.items():\n",
    "        reshaped_mfccs[name] = mfcc.flatten()\n",
    "    return pd.DataFrame(reshaped_mfccs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_all(mfcc_dict):\n",
    "    \"From 2d mfccs to 1d dataframe by averagong along time axis\"\n",
    "    flattened_mfccs = {}\n",
    "    for name, mfcc in mfcc_dict.items():\n",
    "        flattened_mfccs[name] = mfcc.mean(axis=1).flatten()\n",
    "    return pd.DataFrame(flattened_mfccs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(mfcc_dict,crop_dim):\n",
    "    \"\"\"Select random interval and perform crop on mfcc\"\"\"\n",
    "    random_mfccs = {}\n",
    "    for name, mfcc in mfcc_dict.items():\n",
    "        start = randrange(mfcc.shape[1]-crop_dim+1)\n",
    "        random_mfccs[name] = mfcc[:, start:start+crop_dim]\n",
    "    return random_mfccs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_audio(mfcc,crop_dim):\n",
    "    \"\"\"Dicide mfcc in crops with specified length\"\"\"\n",
    "    extra = mfcc.shape[1]%crop_dim\n",
    "    divided_mfcc = np.split(mfcc[:,:mfcc.shape[1]-extra], int((mfcc.shape[1]-extra)/crop_dim), axis=1)\n",
    "    return divided_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_evaluation_input(mfcc_dict, crop_dim, features_path):\n",
    "    \"\"\"From evaluation mfccs to multiple crops of same mfcc with equal length\"\"\"\n",
    "    names=[]\n",
    "    evaluation_input = {}\n",
    "    count=0\n",
    "    for name, mfcc in mfcc_dict.items():\n",
    "        divided_mfcc = divide_audio(mfcc, crop_dim)\n",
    "        for crop in divided_mfcc:\n",
    "            evaluation_input[count]=crop.mean(axis=1).flatten()\n",
    "            names.append(name)\n",
    "            count+=1\n",
    "    evaluation_df = pd.DataFrame(evaluation_input).T.sort_index()\n",
    "    evaluation_df['path']=names\n",
    "    joined_data = evaluation_df.join(features_path.set_index('path'), on='path', how='right').drop(columns=['path'])\n",
    "    joined_data.columns = joined_data.columns.astype(str)\n",
    "    return evaluation_df['path'], joined_data.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_score(data,paths,y_pred,name='-'):\n",
    "    \"\"\"Compute root mean squared error for a given prediction\"\"\"\n",
    "    results = pd.concat((paths.reset_index(drop=True),pd.Series(y_pred, name='Pred')), axis=1)\n",
    "    groups = results.groupby('path')\n",
    "    grouped_results = groups.mean()\n",
    "    joined_results = data.join(grouped_results, on='path')\n",
    "    score = root_mean_squared_error(joined_results['age'], joined_results['Pred'])\n",
    "    print(f\"\\tRoot mean squared error ({name}): \",score)\n",
    "    return score, joined_results['Pred']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files_train = data_long_train['path'].values.tolist()\n",
    "audio_arrays_train,time_sampl_train = load_data(audio_files_train, '../data/audios_development/', SAMPLE_RATE)\n",
    "\n",
    "audio_files_val = data_long_val['path'].values.tolist()\n",
    "audio_arrays_val,time_sampl_val = load_data(audio_files_val, '../data/audios_development/', SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio_files_train_age = data_long_train[(data_long_train['age']<18) | (data_long_train['age']>70)]['path'].values.tolist()\n",
    "#audio_arrays_train_age, time_sampl_train_age = load_data(audio_files_train_age, '../data/audios_development/', SAMPLE_RATE)\n",
    "\n",
    "#audio_files_val_age = data_long_val[(data_long_val['age']<18) | (data_long_val['age']>70)]['path'].values.tolist()\n",
    "#audio_arrays_val_age, time_sampl_val_age = load_data(audio_files_val_age, '../data/audios_development/', SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data preparation and MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMETERS\n",
    "\n",
    "#mfcc hyperparameters\n",
    "n_mfcc=[35]\n",
    "n_fft=66150\n",
    "hop_length=22050\n",
    "#num_time_buckets = 20\n",
    "\n",
    "#MLP hyperparameters\n",
    "crop_dim = [5]\n",
    "max_iter = [300]\n",
    "layerSize=[200]\n",
    "layers=[3] \n",
    "\n",
    "hiddenLayerSizes=[]\n",
    "for i in layerSize:\n",
    "    for j in layers:\n",
    "        hiddenLayerSizes.append([i]*j)\n",
    "\n",
    "GRID = {\n",
    "    'hidden_layer_sizes': hiddenLayerSizes,\n",
    "    'activation': ['relu'],\n",
    "    'alpha': [0.00005],   #Strength of the L2 regularization term. The L2 regularization term is divided by the sample size when added to the loss.\n",
    "    'learning_rate': ['adaptive'],\n",
    "    'batch_size': ['auto'],\n",
    "    'n_iter_no_change': [10],    \n",
    "    'solver': ['adam'],\n",
    "    'learning_rate_init': [0.001],\n",
    "    'tol': [0.0001],\n",
    "    'epsilon': [1e-08],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset and mfcc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tNumber of mfcc rows:  35\n",
      "\n",
      "\tCrop dimension:  5\n",
      "\n",
      "\tMax iterations:  300\n",
      "{'activation': 'relu', 'alpha': 5e-05, 'batch_size': 'auto', 'epsilon': 1e-08, 'hidden_layer_sizes': [200, 200, 200], 'learning_rate': 'adaptive', 'learning_rate_init': 0.001, 'n_iter_no_change': 10, 'solver': 'adam', 'tol': 0.0001}\n",
      "\tRoot mean squared error (train):  10.888800930051223\n",
      "\tRoot mean squared error (val):  13.517563181462533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_scores =[]\n",
    "val_scores =[]\n",
    "# Iteration on possible numbers of mfcc rows\n",
    "for mfcc_rows in n_mfcc:\n",
    "    print('\\n\\tNumber of mfcc rows: ',mfcc_rows)\n",
    "    # Compute mfcc for train recordings\n",
    "    mfccs_train = {}\n",
    "    for name_train,audio_train in audio_arrays_train.items():\n",
    "        mfccs_train[name_train] = lb.feature.mfcc(y=audio_train, sr=SAMPLE_RATE, n_mfcc=mfcc_rows, n_fft=n_fft,hop_length=hop_length)\n",
    "    # Compute mfcc for validation recordings\n",
    "    mfccs_val = {}\n",
    "    for name_val,audio_val in audio_arrays_val.items():\n",
    "        mfccs_val[name_val] = lb.feature.mfcc(y=audio_val, sr=SAMPLE_RATE, n_mfcc=mfcc_rows, n_fft=n_fft,hop_length=hop_length)\n",
    "    # Iteration on possible crop widths\n",
    "    for crop in crop_dim:\n",
    "        print('\\n\\tCrop dimension: ', crop)\n",
    "        # Iteration on possible numbers of iterations\n",
    "        for it in max_iter:\n",
    "            print('\\n\\tMax iterations: ', it)\n",
    "            #Iterate on each combination of the grid search\n",
    "            for g in ParameterGrid(GRID):\n",
    "                print(g)\n",
    "                # Initialize model\n",
    "                mlp_mfcc = MLPRegressor(random_state=RANDOM_SEED, shuffle=True,)\n",
    "                mlp_mfcc.set_params(**g)\n",
    "                # Model iterations\n",
    "                for iter in range(it):\n",
    "                    if iter%1 == 0:\n",
    "                        # From mfcc crop to features\n",
    "                        reshaped_mfccs = flatten_all(random_crop(mfccs_train,crop))\n",
    "                        joined_data = data_long_train.join(reshaped_mfccs, on='path').drop(columns=['path'])\n",
    "                        X = joined_data.drop(columns=['age'])                        \n",
    "                        X.columns = X.columns.astype(str)\n",
    "                    mlp_mfcc.partial_fit(X.sort_index(axis=1), joined_data['age'])\n",
    "                #Train prediction\n",
    "                paths_train, X_train = create_evaluation_input(mfccs_train, crop, data_long_train)\n",
    "                y_pred_train = mlp_mfcc.predict(X_train.drop(columns=['age']))\n",
    "                score_train = find_score(data_long_train,paths_train,y_pred_train,name='train')\n",
    "                train_scores.append(score_train)\n",
    "                #Validation prediction\n",
    "                paths_val, X_val = create_evaluation_input(mfccs_val, crop, data_long_val)\n",
    "                y_pred_val = mlp_mfcc.predict(X_val.drop(columns=['age']))\n",
    "                score_val = find_score(data_long_val,paths_val,y_pred_val,name='val')\n",
    "                val_scores.append(score_val)\n",
    "                print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_scores =[]\\nval_scores =[]\\nfor mfcc_rows in n_mfcc:\\n    print('\\n\\tNumber of mfcc rows: ',mfcc_rows)\\n    mfccs_train = {}\\n    mfccs_train_age = {}\\n    for name_train,audio_train in audio_arrays_train.items():\\n        mfccs_train[name_train] = lb.feature.mfcc(y=audio_train, sr=SAMPLE_RATE, n_mfcc=mfcc_rows, n_fft=n_fft,hop_length=hop_length)\\n    for name_train,audio_train in audio_arrays_train_age.items():\\n        mfccs_train_age[name_train] = lb.feature.mfcc(y=audio_train, sr=SAMPLE_RATE, n_mfcc=mfcc_rows, n_fft=n_fft,hop_length=hop_length)\\n    mfccs_val = {}\\n    mfccs_val_age = {}\\n    for name_val,audio_val in audio_arrays_val.items():\\n        mfccs_val[name_val] = lb.feature.mfcc(y=audio_val, sr=SAMPLE_RATE, n_mfcc=mfcc_rows, n_fft=n_fft,hop_length=hop_length)\\n    for name_val,audio_val in audio_arrays_val_age.items():\\n        mfccs_val_age[name_val] = lb.feature.mfcc(y=audio_val, sr=SAMPLE_RATE, n_mfcc=mfcc_rows, n_fft=n_fft,hop_length=hop_length)\\n    \\n    for crop in crop_dim:\\n        print('\\n\\tCrop dimension: ', crop)\\n        for it in max_iter:\\n            print('\\n\\tMax iterations: ', it)\\n            for g in ParameterGrid(GRID):\\n                print(g)\\n                mlp_mfcc = MLPRegressor(random_state=RANDOM_SEED, shuffle=True,)\\n                mlp_mfcc.set_params(**g)\\n                for iter in range(it):\\n                    if iter%5 == 0:\\n                        reshaped_mfccs = flatten_all(random_crop(mfccs_train,crop))\\n                        reshaped_mfccs_age = flatten_all(random_crop(mfccs_train_age,crop))\\n                        joined_data = data_long_train.join(reshaped_mfccs, on='path').drop(columns=['path'])\\n                        joined_data_age = data_long_train[(data_long_train['age']<18) | (data_long_train['age']>70)].join(reshaped_mfccs_age, on='path').drop(columns=['path'])\\n                        join = pd.concat([joined_data, joined_data_age, joined_data_age, joined_data_age])\\n                        X = join.drop(columns=['age'])\\n                        X.columns = X.columns.astype(str)\\n                    mlp_mfcc.partial_fit(X.sort_index(axis=1), join['age'])\\n                #Train\\n                paths_train, X_train = create_evaluation_input(mfccs_train, crop, data_long_train)\\n                y_pred_train = mlp_mfcc.predict(X_train.drop(columns=['age']))\\n                score_train = find_score(data_long_train,paths_train,y_pred_train,name='train')\\n                train_scores.append(score_train)\\n                #Validation\\n                paths_val, X_val = create_evaluation_input(mfccs_val, crop, data_long_val)\\n                y_pred_val = mlp_mfcc.predict(X_val.drop(columns=['age']))\\n                score_val = find_score(data_long_val,paths_val,y_pred_val,name='val')\\n                val_scores.append(score_val)\\n                print()\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "train_scores =[]\n",
    "val_scores =[]\n",
    "for mfcc_rows in n_mfcc:\n",
    "    print('\\n\\tNumber of mfcc rows: ',mfcc_rows)\n",
    "    mfccs_train = {}\n",
    "    mfccs_train_age = {}\n",
    "    for name_train,audio_train in audio_arrays_train.items():\n",
    "        mfccs_train[name_train] = lb.feature.mfcc(y=audio_train, sr=SAMPLE_RATE, n_mfcc=mfcc_rows, n_fft=n_fft,hop_length=hop_length)\n",
    "    for name_train,audio_train in audio_arrays_train_age.items():\n",
    "        mfccs_train_age[name_train] = lb.feature.mfcc(y=audio_train, sr=SAMPLE_RATE, n_mfcc=mfcc_rows, n_fft=n_fft,hop_length=hop_length)\n",
    "    mfccs_val = {}\n",
    "    mfccs_val_age = {}\n",
    "    for name_val,audio_val in audio_arrays_val.items():\n",
    "        mfccs_val[name_val] = lb.feature.mfcc(y=audio_val, sr=SAMPLE_RATE, n_mfcc=mfcc_rows, n_fft=n_fft,hop_length=hop_length)\n",
    "    for name_val,audio_val in audio_arrays_val_age.items():\n",
    "        mfccs_val_age[name_val] = lb.feature.mfcc(y=audio_val, sr=SAMPLE_RATE, n_mfcc=mfcc_rows, n_fft=n_fft,hop_length=hop_length)\n",
    "    \n",
    "    for crop in crop_dim:\n",
    "        print('\\n\\tCrop dimension: ', crop)\n",
    "        for it in max_iter:\n",
    "            print('\\n\\tMax iterations: ', it)\n",
    "            for g in ParameterGrid(GRID):\n",
    "                print(g)\n",
    "                mlp_mfcc = MLPRegressor(random_state=RANDOM_SEED, shuffle=True,)\n",
    "                mlp_mfcc.set_params(**g)\n",
    "                for iter in range(it):\n",
    "                    if iter%5 == 0:\n",
    "                        reshaped_mfccs = flatten_all(random_crop(mfccs_train,crop))\n",
    "                        reshaped_mfccs_age = flatten_all(random_crop(mfccs_train_age,crop))\n",
    "                        joined_data = data_long_train.join(reshaped_mfccs, on='path').drop(columns=['path'])\n",
    "                        joined_data_age = data_long_train[(data_long_train['age']<18) | (data_long_train['age']>70)].join(reshaped_mfccs_age, on='path').drop(columns=['path'])\n",
    "                        join = pd.concat([joined_data, joined_data_age, joined_data_age, joined_data_age])\n",
    "                        X = join.drop(columns=['age'])\n",
    "                        X.columns = X.columns.astype(str)\n",
    "                    mlp_mfcc.partial_fit(X.sort_index(axis=1), join['age'])\n",
    "                #Train\n",
    "                paths_train, X_train = create_evaluation_input(mfccs_train, crop, data_long_train)\n",
    "                y_pred_train = mlp_mfcc.predict(X_train.drop(columns=['age']))\n",
    "                score_train = find_score(data_long_train,paths_train,y_pred_train,name='train')\n",
    "                train_scores.append(score_train)\n",
    "                #Validation\n",
    "                paths_val, X_val = create_evaluation_input(mfccs_val, crop, data_long_val)\n",
    "                y_pred_val = mlp_mfcc.predict(X_val.drop(columns=['age']))\n",
    "                score_val = find_score(data_long_val,paths_val,y_pred_val,name='val')\n",
    "                val_scores.append(score_val)\n",
    "                print()\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_environment_DSL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
